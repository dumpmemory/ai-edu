用搜索法
遍历6个状态下（s0-s5）的所有策略选择


<center>
<img src="./img/mdp-8.png">

图 7
</center>

而图 x 所示的最佳选择是第一轮射击蓝色气球，第二轮继续射击蓝色气球。

但是，图 x 的各个节点的价值函数，包括状态价值函数和动作价值函数，是在一个固定的策略下计算出来的，即：

$$
\pi(a \mid s)=
\begin{cases}
0.4, & a=射击红球
\\
0.6, & a=射击蓝球
\end{cases}
$$

前面也提到过，这个策略是通过统计游客的行为而得到的。意味着在100个游客中，有40个游客会选择射击红色气球，另外60个游客会选择射击蓝色气球，两轮射击都是如此。

所以，这还是没有回到我们在最开始提出的问题：那么你做为一个聪明的游客该如何选择呢？因为你不可能把一颗子弹分成 0.4:0.6，所以你必须二选一，同时记住你的目的是达到最大收益。

一个不怎么“聪明”的游客也会想到应该连续两次选择射击红球才有可能得到 6 分的奖励，在这里所谓“聪明”与否完全是对风险的判断以及自身实力的评估，从而选择连续两次射击蓝球而不是红球，但这不是强化学习的范畴。

所以，让我们回到强化学习领域来，看看最佳的策略应该是什么。

在马尔可夫决策过程过程的概念中学习过，所谓策略就是在每个状态上采取什么动作，从而使收益最大化。在图 x 中，一共有 6 个有效的状态（$s_0,\cdots,s_5$) ，在每个状态上的策略有两种动作选择（红球或蓝球），这样一共有 $2^6$ 种选择。可以推广到一般情况：如果状态空间为 $S$，动作空间为 $A$，则策略组合是 $A^S$ 种。

对于这个简单的问题来说，即使用遍历的方法，也很容易快速得到结果。所以，我们先用最笨但是最准确的遍历来得到评估的基准。


