## 马尔可夫决策过程

### 射击气球问题

我们仍然以前面学过的、熟悉的状态转移问题来开始本章的学习。

有一天你去游乐场，有一个游戏的规则是这样的：

1. 游客花 4 元钱买 2 颗橡皮子弹
2. 墙上有两个气球，一个大的，一个小的
3. 击中大气球可以得到小奖，价值 1 元
4. 击中小气球可以得到小奖，价值 3 元

各个状态的转移概率如图 1 所示。

<center>
<img src="./img/shoot-1.png">

图 1
</center>

按游乐场老板的统计，第一发子弹：

- 游客中大奖的概率是 0.1
- 游客脱靶的概率是 0.3
- 游客中小奖的概率是 0.6

而第二发字典根据第一发子弹的结果而有所不同：

1. 如果第一发子弹中大奖
    - 第二发子弹继续中大奖的概率是 0.2，比初始的 0.1 提高了一倍，因为游客有经验了；
    - 第二发子弹脱靶的概率是 0.2，比初始的 0.3 要低；
    - 第二发子弹中小奖的概率不变，仍然是 0.6；
2. 如果第一发子弹脱靶
    第二发子弹的情况会和第一发子弹的初始概率一样，还是 0.1, 0.3, 0.6；
3. 如果第一发子弹中小奖
    - 第二发子弹中大奖的概率不变，仍然是 0.1；
    - 第二发子弹脱靶的概率是 0.2，比初始的 0.3 要低；
    - 第二发子弹继续中小奖的概率提高到 0.7。

那么一个聪明的游客该如何选择呢？


利用前面学到过的知识，可以计算第一发子弹时的三个状态，哪一个的状态价值函数值最大。

<center>
<img src="./img/shoot-2.png">

图 2 错误的状态转移图
</center>

其实这个问题的状态转移图应该如图 3 所示，是一个有向无环图。

<center>
<img src="./img/shoot-3.png">

图 3 正确的的状态转移图
</center>

说明

1. 虽然状态中有四个“大奖”，四个“小奖”，四个“脱靶”，但是这四个状态不是同一个状态，只是名字一样而已，在图 3 中特意用序号把它们都区分开了。其中：
    - 0 号为开始状态；
    - 1~3 号为二级状态；
    - 4~12 号为三级状态。
2. 开始状态需要有个 -4 的奖励，因为一开始游客是花 4 元钱买了两颗橡皮子弹。
3. 所有的三级状态（序号4~12），最后都接一个终止状态 T。

为什么四个“大奖”不是一个状态呢？

从“开始”状态看，第一发子弹有 0.1 的概率到达 1 号“大奖”状态；而第二发子弹有 0.2 的概率到达 4 号“大奖”状态。如果游客还有第三发子弹，那么中大奖的概率在第三轮还会提高。就好比从一楼上 10 级台阶到二楼，台阶可以定义为 1 到 10；而二楼到三楼同样有 10 级台阶，也定义为 1 到 10，但所处的楼层不一样。

我们从后向前计算一下各个状态的价值函数，由于是个有向无环的图，所以根据式 xxx 很简单就可以得到（本例中折扣应该为 1）：

首先，终止状态 $v_T = 0$。

然后 $v_4$ 为例：$v_4 = R_4 + \gamma 1.0 \times V_T = 3+1\times0=3$。其它三级状态的计算方法相同。

$$
\begin{cases}
v_T=0
\\
v_4=3, v_5 = 0, v_6 = 1, 
\\
v_7=3, v_8=0, v_9=1,
\\
v_{10}=3, v_{11}=0, v_{12}=1,
\\
v_1 = 3 + 0.2v_4+0.2v_5+0.6v_6=4.2
\\
v_2 = 0 + 0.1v_7+0.3v_8+0.6v_9=0.9
\\
v_3 = 1 + 0.1v_{10}+0.2v_{11}+0.7v_{12}=1.8
\\
v_0 = -4 + 0.1v_1+0.3v_2+0.6v_3=-2.23
\end{cases}
$$

所以，从统计学的观点看，只要游客买了子弹，就已经亏了，老板是稳赚不赔的。

那么游客应该怎么选择呢？

- 虽然 $V_{1}=4.2$ 状态价值最高，但是到达 $s_1$ 只有 0.1 的概率，可以理解为游客的收益是：$0.1\times4.2=0.42$元。
- $s_2$ 的收益是 $0.3\times0.9=0.27$ 元。
- $s_3$ 的收益是 $0.6\times1.8=1.08$ 元。

所以游客第一次射击时应该选择 $s_3$，即“小奖”状态，然后第二次射击时继续选择“小奖”状态。



MDP - Markov Decision Process

前面章节中，曾经提到过两种奖励函数的方式：

- 面向结果，基于状态的奖励方法

    把过程分割成状态，把状态都看作是静止的瞬间。

- 面向过程，基于过程的奖励方法

    把看似静止的状态用过程来连接，形成时间轴上的前后关系。

任何事物都不是静止不动的，而是处于运动状态，只不过有的快有的慢。对于非智能物体，如空气流水等的运动，属于物理学范畴；而对于智能物体，如动物、人类等的行为，就属于强化学习的研究范畴了。



